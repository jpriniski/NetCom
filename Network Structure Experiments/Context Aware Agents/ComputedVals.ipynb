{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cc0aa4d-e2e8-42fd-8cc4-b2ee9f1cc53a",
   "metadata": {},
   "source": [
    "## Values Computed that may be used in other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0610b957-a77b-4271-bfbb-9c21242702ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./SimPreliminaries.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2faf95-eea5-4c2d-9bb3-43a15d3bd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_entropy(exp_lst):\n",
    "    delta_entropies = []\n",
    "    for exp in exp_lst:\n",
    "        delta_entropies.append(np.diff(np.array(compute_entropy(exp))))\n",
    "        \n",
    "    avg_entropy = np.mean(delta_entropies, axis=0)\n",
    "    return avg_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f26966a-c922-47de-b09f-71d883c86a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(df):\n",
    "    pivot_df = df.pivot(index='id', columns='TrialNumber', values='Response')\n",
    "    entropy_values = []\n",
    "\n",
    "    for column in pivot_df.columns:\n",
    "        counts = pd.Series(pivot_df[column]).value_counts()\n",
    "        proportions = counts / counts.sum()\n",
    "        \n",
    "        entropy = -np.sum(proportions * np.log2(proportions))\n",
    "        entropy_values.append(entropy)\n",
    "\n",
    "    return entropy_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ad7d9f-2014-4a97-b658-56bcce8dde7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "props20 = np.array([1/20 for i in range(20)])\n",
    "normalize20 = -np.sum(props20 * np.log2(props20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e342d8f-ba40-426a-91c4-a63a19aff2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "props50 = np.array([1/50 for i in range(50)])\n",
    "normalize50 = -np.sum(props50 * np.log2(props50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0e58ce-1420-4b0b-968c-47c29ff2d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "props100 = np.array([1/100 for i in range(100)])\n",
    "normalize100 =-np.sum(props100 * np.log2(props100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4acf73c3-1b56-45a1-80a6-0a8d05fd0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_face = [[f20h1, f20h2, f20h3], [f50h1, f50h2, f50h3]]\n",
    "spat_face = [[f20s1, f20s2, f20s3], [f50s1, f50s2, f50s3]]\n",
    "homo_ht = [[h20h1, h20h2, h20h3], [h50h1, h50h2, h50h3], [h100h1]]\n",
    "spat_ht = [[h20s1, h20s2, h20s3], [h50s1, h50s2, h50s3], [h100s1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2df98c-3e6f-4b76-8861-6bde94654795",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizers = [normalize20, normalize50, normalize100]\n",
    "\n",
    "hf_entropies = []\n",
    "for i in range(len(homo_face)):\n",
    "    for df in homo_face[i]:\n",
    "        ent = np.array(compute_entropy(df))\n",
    "        normalized = ent/normalizers[i]\n",
    "        \n",
    "        hf_entropies.append(normalized)\n",
    "        \n",
    "hf_avg_normalized = np.mean(hf_entropies, axis=0)\n",
    "#hf_avg_normalized\n",
    "\n",
    "sf_entropies = []\n",
    "for i in range(len(spat_face)):\n",
    "    for df in spat_face[i]:\n",
    "        ent = np.array(compute_entropy(df))\n",
    "        normalized = ent/normalizers[i]\n",
    "        \n",
    "        sf_entropies.append(normalized)\n",
    "        \n",
    "sf_avg_normalized = np.mean(sf_entropies, axis=0)\n",
    "\n",
    "hh_entropies = []\n",
    "for i in range(len(homo_ht)):\n",
    "    for df in homo_ht[i]:\n",
    "        ent = np.array(compute_entropy(df))\n",
    "        normalized = ent/normalizers[i]\n",
    "        \n",
    "        hh_entropies.append(normalized)\n",
    "        \n",
    "hh_avg_normalized = np.mean(hh_entropies, axis=0)\n",
    "\n",
    "sh_entropies = []\n",
    "for i in range(len(spat_ht)):\n",
    "    for df in spat_ht[i]:\n",
    "        ent = np.array(compute_entropy(df))\n",
    "        normalized = ent/normalizers[i]\n",
    "        \n",
    "        sh_entropies.append(normalized)\n",
    "        \n",
    "sh_avg_normalized = np.mean(sh_entropies, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053d0d2b-05ba-4e1e-ad06-e6ced2118692",
   "metadata": {},
   "outputs": [],
   "source": [
    "homo_face = [[f20h1, f20h2, f20h3], [f50h1, f50h2, f50h3]]\n",
    "spat_face = [[f20s1, f20s2, f20s3], [f50s1, f50s2, f50s3]]\n",
    "homo_ht = [[h20h1, h20h2, h20h3], [h50h1, h50h2, h50h3], [h100h1]]\n",
    "spat_ht = [[h20s1, h20s2, h20s3], [h50s1, h50s2, h50s3], [h100s1]]\n",
    "\n",
    "face_exp_dfs = [f20h1, f20h2, f20h3, f20s1, f20s2, f20s3, f50h1, f50h2, f50h3, f50s1, f50s2, f50s3]\n",
    "hashtag_exp_dfs = [h20h1, h20h2, h20h3, h20s1, h20s2, h20s3, h50h1, h50h2, h50h3, h50s1, h50s2, h50s3, h100h1, h100s1]\n",
    "\n",
    "exp_df_dict = {'Homogeneous Face20': [f20h1, f20h2, f20h3], 'Spatial Face20': [f20s1, f20s2, f20s3],\n",
    "               'Homogeneous Face50':[f50h1, f50h2, f50h3], 'Spatial Face50': [f50s1, f50s2, f50s3],\n",
    "               'Homogeneous Hashtag20':[h20h1, h20h2, h20h3], 'Spatial Hashtag20': [h20s1, h20s2, h20s3],\n",
    "               'Homogeneous Hashtag50': [h50h1, h50h2, h50h3], 'Spatial Hashtag50': [h50s1, h50s2, h50s3],\n",
    "               'Homogeneous Face': [f20h1, f20h2, f20h3]+[f50h1, f50h2, f50h3], \n",
    "               'Spatial Face': [f20s1, f20s2, f20s3]+[f50s1, f50s2, f50s3], \n",
    "               'Homogeneous Hashtag': [h20h1, h20h2, h20h3]+[h50h1, h50h2, h50h3]+[h100h1],\n",
    "               'Spatial Hashtag': [h20s1, h20s2, h20s3]+[h50s1, h50s2, h50s3]+[h100s1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765adcef-f21c-4d37-9e17-5bb3e6d27a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_avg_entropies=[hf_avg_normalized, sf_avg_normalized, hh_avg_normalized, sh_avg_normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7a90cb-b27d-4a94-bd10-f5dfec6b6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_homo = [[h20h1, h20h2, h20h3],[h50h1, h50h2, h50h3], [h100h1]]\n",
    "\n",
    "bn_arrs = []\n",
    "ec_arrs = []\n",
    "rs_arrs = []\n",
    "rp_arrs = []\n",
    "\n",
    "s = 0\n",
    "for size in ht_homo:\n",
    "    for df in size:\n",
    "        grouped_trial = df.groupby(['TrialNumber', 'DecisionType']).size().unstack(fill_value=0) # group the data by trial and decision type columns for plotting\n",
    "        grouped_trial = grouped_trial.loc[:, grouped_trial.sum().sort_values(ascending=False).index] # Sort columns by total count\n",
    "        if s == 0:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/20)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/20)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/20)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/20)\n",
    "            \n",
    "        elif s==1:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/50)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/50)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/50)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/50)\n",
    "        else:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/100)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/100)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/100)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/100)\n",
    "\n",
    "hh_avg_bn = np.mean(bn_arrs, axis=0) # proportion\n",
    "hh_avg_ec = np.mean(ec_arrs, axis=0)\n",
    "hh_avg_rs = np.mean(rs_arrs, axis=0)\n",
    "hh_avg_rp = np.mean(rp_arrs, axis=0)\n",
    "\n",
    "hh_proportions = [hh_avg_bn, hh_avg_ec, hh_avg_rs, hh_avg_rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da0d189-e00d-4fc6-a46a-3717adef6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_spat = [[h20s1, h20s2, h20s3],[h50s1, h50s2, h50s3], [h100s1]]\n",
    "\n",
    "bn_arrs = []\n",
    "ec_arrs = []\n",
    "rs_arrs = []\n",
    "rp_arrs = []\n",
    "\n",
    "s = 0\n",
    "for size in ht_spat:\n",
    "    for df in size:\n",
    "        grouped_trial = df.groupby(['TrialNumber', 'DecisionType']).size().unstack(fill_value=0) # group the data by trial and decision type columns for plotting\n",
    "        grouped_trial = grouped_trial.loc[:, grouped_trial.sum().sort_values(ascending=False).index] # Sort columns by total count\n",
    "        if s == 0:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/20)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/20)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/20)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/20)\n",
    "            \n",
    "        elif s==1:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/50)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/50)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/50)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/50)\n",
    "        else:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/100)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/100)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/100)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/100)\n",
    "\n",
    "hs_avg_bn = np.mean(bn_arrs, axis=0) # proportion\n",
    "hs_avg_ec = np.mean(ec_arrs, axis=0)\n",
    "hs_avg_rs = np.mean(rs_arrs, axis=0)\n",
    "hs_avg_rp = np.mean(rp_arrs, axis=0)\n",
    "\n",
    "hs_proportions = [hs_avg_bn, hs_avg_ec, hs_avg_rs, hs_avg_rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d0026e-e02c-413a-bc7e-5e6cbe942c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_homo = [[f20h1, f20h2, f20h3],[f50h1, f50h2, f50h3]]\n",
    "\n",
    "bn_arrs = []\n",
    "ec_arrs = []\n",
    "rs_arrs = []\n",
    "rp_arrs = []\n",
    "\n",
    "s = 0\n",
    "for size in face_homo:\n",
    "    for df in size:\n",
    "        grouped_trial = df.groupby(['TrialNumber', 'DecisionType']).size().unstack(fill_value=0) # group the data by trial and decision type columns for plotting\n",
    "        grouped_trial = grouped_trial.loc[:, grouped_trial.sum().sort_values(ascending=False).index] # Sort columns by total count\n",
    "        if s == 0:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/20)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/20)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/20)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/20)\n",
    "            \n",
    "        else:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/50)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/50)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/50)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/50)\n",
    "            \n",
    "    s+=1\n",
    "\n",
    "fh_avg_bn = np.mean(bn_arrs, axis=0) # proportion\n",
    "fh_avg_ec = np.mean(ec_arrs, axis=0)\n",
    "fh_avg_rs = np.mean(rs_arrs, axis=0)\n",
    "fh_avg_rp = np.mean(rp_arrs, axis=0)\n",
    "\n",
    "fh_proportions = [fh_avg_bn, fh_avg_ec, fh_avg_rs, fh_avg_rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "246ce4da-bcba-4217-95c8-fdb23e8be1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_spat = [[f20s1, f20s2, f20s3],[f50s1, f50s2, f50s3]]\n",
    "\n",
    "bn_arrs = []\n",
    "ec_arrs = []\n",
    "rs_arrs = []\n",
    "rp_arrs = []\n",
    "\n",
    "s = 0\n",
    "for size in face_spat:\n",
    "    for df in size:\n",
    "        grouped_trial = df.groupby(['TrialNumber', 'DecisionType']).size().unstack(fill_value=0) # group the data by trial and decision type columns for plotting\n",
    "        grouped_trial = grouped_trial.loc[:, grouped_trial.sum().sort_values(ascending=False).index] # Sort columns by total count\n",
    "        if s == 0:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/20)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/20)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/20)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/20)\n",
    "            \n",
    "        else:\n",
    "            bn_arrs.append(grouped_trial['BN'].to_numpy()/50)\n",
    "            ec_arrs.append(grouped_trial['EC'].to_numpy()/50)\n",
    "            rs_arrs.append(grouped_trial['RS'].to_numpy()/50)\n",
    "            rp_arrs.append(grouped_trial['RP'].to_numpy()/50)\n",
    "    s+=1\n",
    "\n",
    "fs_avg_bn = np.mean(bn_arrs, axis=0) # proportion\n",
    "fs_avg_ec = np.mean(ec_arrs, axis=0)\n",
    "fs_avg_rs = np.mean(rs_arrs, axis=0)\n",
    "fs_avg_rp = np.mean(rp_arrs, axis=0)\n",
    "\n",
    "fs_proportions = [fs_avg_bn, fs_avg_ec, fs_avg_rs, fs_avg_rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61458c1b-120b-4e21-bffe-1f52bbf85b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15c554-3e38-4ac5-91cd-67685c75b757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
